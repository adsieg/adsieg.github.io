{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import os \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# function to clean text\n",
    "def review_to_words(raw_review):\n",
    "    \n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review) \n",
    "    \n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 3. Remove Stopwords. In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]  #returns a list \n",
    "\n",
    "    # 5. Stem words. Need to define porter stemmer above\n",
    "    singles = [stemmer.stem(word) for word in meaningful_words]\n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, and return the result.\n",
    "    return( \" \".join( singles ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/adsieg/Desktop/BNP/external_data\"\n",
    "os.chdir(path)\n",
    "\n",
    "data_orx = pd.read_csv('ORX_news_clean.csv')\n",
    "data_sas = pd.read_csv('SAS_clean.csv')\n",
    "\n",
    "text_orx = data_orx['Digest text']\n",
    "text_sas = data_sas['Description of Event']\n",
    "\n",
    "text_total = pd.concat([text_orx, text_sas])\n",
    "text_total = text_total.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        On 1 July 2014, BNP pleaded guilty to falsifyi...\n",
       "1        On 25 January 2016, JPMorgan agreed to a USD 1...\n",
       "2        A DEEP DIVE IS NOW AVAILABLE FOR THIS LOSS EVE...\n",
       "3        A DEEP DIVE IS NOW AVAILABLE FOR THIS LOSS EVE...\n",
       "4        A DEEP DIVE IS NOW AVAILABLE FOR THIS LOSS EVE...\n",
       "5        On 20 October 2015, La Tribune announced that ...\n",
       "6        Western Union will pay USD 651 million (EUR) a...\n",
       "7        ING Bank N.V. is to pay USD 619 million (EUR 4...\n",
       "8        The Bank of Tokyo-Mitsubishi UFJ has been fine...\n",
       "9        Credit Suisse has agreed to forfeit USD 536 mi...\n",
       "10       On 26 January 2018, the Japanese cryptocurrenc...\n",
       "11       The former ABN AMRO Bank, now the Royal Bank o...\n",
       "12       On 28 February 2014 MT Gox filed for bankruptc...\n",
       "13       In February 2018, the US Office of the Comptro...\n",
       "14       Lloyds TSB Bank has agreed to forfeit USD 350 ...\n",
       "15       Barclays has paid a total of USD 300.5 million...\n",
       "16       Deutsche Bank is to pay a USD 258 million (EUR...\n",
       "17       Banamex USA has paid a total of USD 237.4 mill...\n",
       "18       On 15 December 2016, the New York Department o...\n",
       "19       On 7 September 2017, the New York Department o...\n",
       "20       Agricultural Bank of China (ABC) will pay a US...\n",
       "21       Mega International Commercial Bank (Mega Bank)...\n",
       "22       On 8 February 2018,Â Italian cryptocurrency exc...\n",
       "23       Wachovia Bank has agreed to pay USD 160 millio...\n",
       "24       On 7 November 2013 Deutsche Boerse announced t...\n",
       "25       On 20 January 2009, Heartland Payment Systems ...\n",
       "26       Western Union has agreed to pay USD 133 millio...\n",
       "27       On 26 July 2017, the US Financial Crimes Enfor...\n",
       "28       FirstRand Bank (FNB) has recorded a ZAR 915 mi...\n",
       "29       Royal Bank of Scotland (RBS) has been fined US...\n",
       "                               ...                        \n",
       "19456    In March 2004, Central Bank of India, an India...\n",
       "19457    In March 2004, Bank of Uganda, a Ugandan finan...\n",
       "19458    In March 2012, National Bank of Pakistan, a Pa...\n",
       "19459    In July 2008, Barclays Bank PLC Mauritius, a M...\n",
       "19460    In September 2015, MCB Bank Ltd, a Pakistani f...\n",
       "19461    In September 2011, Central Bank of India, an I...\n",
       "19462    In February 2007, BanColombia SA, a Colombian ...\n",
       "19463    In December 2017, Mega International Commercia...\n",
       "19464    In December 2017, Bank of Taiwan, a Taiwanese ...\n",
       "19465    In May 2004, Standard Bank Namibia, a Namibian...\n",
       "19466    In May 2004, LNB Bancorp Inc, a US financial i...\n",
       "19467    In December 2004, Anchor BanCorp Wisconsin, a ...\n",
       "19468    In April 2004, Bank of Korea, the South Korean...\n",
       "19469    In April 2012, ONB Bank and Trust Co, a US fin...\n",
       "19470    In January 2009, State Bank of India, an India...\n",
       "19471    In March 2008, Oriental Bank of Commerce, an I...\n",
       "19472    In May 2006, First National Bank of Omaha, a U...\n",
       "19473    In September 2007, National Australia Bank Ltd...\n",
       "19474    In February 2007, Union Bank of Taiwan, a Taiw...\n",
       "19475    In August 2007, Bank Leumi le-Israel BM, an Is...\n",
       "19476    In August 2012, Tennessee Commerce Bank, a US ...\n",
       "19477    In April 2009, International Bank of Commerce,...\n",
       "19478    In June 2008, Bendigo Bank Ltd, an Australian ...\n",
       "19479    In January 2010, Oceanic Bank International PL...\n",
       "19480    In June 2010, FirstBank of Puerto Rico, a Puer...\n",
       "19481    In June 2010, Banco Bilbao Vizcaya Argentaria ...\n",
       "19482    In May 2011, Bank SinoPac, a Taiwan financial ...\n",
       "19483    In April 2013, Central Bank of Kansas City, a ...\n",
       "19484    In June 2014, Citizens Bank of Pennsylvania, a...\n",
       "19485    In September 2016, Bank of Liuzhou Co Ltd, a C...\n",
       "Length: 19486, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = str(text_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'join' requires a 'str' object but received a 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-385183aaa4fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: descriptor 'join' requires a 'str' object but received a 'Series'"
     ]
    }
   ],
   "source": [
    "total2 = str.join(text_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['juli bnp plead guilti falsifi busi record conspiraci believ bnp plead guilti feder court conspiraci juli june announc bnp pariba reach usd billion eur billion court settlement us author us econom sanction violat may us judg sentenc bnp five year probat settlement relat usd billion transact conduct switzerland process countri us sanction sanction countri includ iran sudan cuba accord reuter bnp abl avoid sanction relat transfer iran cuba strip inform wire transfer allow pass us system without rais flag sudan bnp admit set elabor payment structur rout transact satellit bank disguis origin reuter report prior reach settlement bnp implement new complianc control procedur mani place time settlement includ implement new depart known group financi secur us ensur bnp global compli us regul regard intern sanction embargo ensur usd flow within bnp process control via new york branch februari bnp pariba announc set asid usd billion provis cover expect legal cost provis prompt bnp report lowest quarterli result sinc fall per cent q bank net incom decreas eur million eur million later bnp said q result discuss taken place first quarter demonstr high degre uncertainti exist natur amount penalti us author could impos bank fine could far excess amount provis wall street journal report april fine could high usd billion bloomberg report may fine could usd billion accord statement bnp websit bnp includ except charg eur billion q result financi time report half fine shall award manhattan district attorney new york depart financi servic nydf nydf receiv usd billion second half shall distribut amongst depart justic offic foreign asset control januari busi within bnp seen directli respons violat sanction suspend clear usd transact year furthermor execut requir leav bank includ chief oper offic georg chodron de courcel bank includ hsbc ing standard charter alreadi paid billion fine resolv similar us sanction breach claim transact carri cuba iran libya myanmar sudan updat april ad paragraph may ad possibl loss amount usd billion paragraph june usd billion settlement reach loss amount chang inform within text alter reflect settlement inform septemb role firm chang ls ls line orr updat may bnp sentenc five year probat first paragraph alter june countri chang franc unit state follow advic orx definit work group octob industri loss event us sanction violat ad',\n",
       " 'januari jpmorgan agre usd billion settlement lehman brother alleg made wrong transact includ inappropri call collater invest compani collaps septemb lehman file lawsuit jpmorgan may alleg bank inappropri took hold usd billion lehman collater final day februari jpmorgan agre pay addit usd million bring total fine usd billion eur billion lehman claim final day file bankruptci jpmorgan use posit lehman primari clear bank extract liquid invest bank misappli collater provid hold compani day file bankruptci lehman sold broker dealer unit barclay follow deal jpmorgan claim advanc usd billion former lehman unit left unpaid jpmorgan face stuck illiquid secur barclay want lehman later alleg jpmorgan decid use usd billion collater pledg lehman hold compani includ usd billion cash day collaps septemb cover posit furthermor time lehman bankruptci approxim deriv trade still open lehman jpmorgan lehman alleg close posit jpmorgan improperli increas claim hundr million dollar add charg account transact cost hypothet replac transact enter jpmorgan time close motion approv settlement state would resolv signific proport usd billion lawsuit jpmorgan settlement also resolv usd billion deriv relat claim reduc usd includ lehman claim jpmorgan last minut closeout thousand deriv contract lehman bankruptci furthermor counterclaim fraudul induc indemnif jpmorgan lehman resolv settlement jpmorgan agre pay usd billion lehman also receiv right withdraw usd million debtor deposit result settlement allow almost usd new distribut lehman creditor accord financi time settlement expect materi impact jpmorgan earn februari lehman submit motion new york southern district bankruptci court ask approv januari settlement lehman jpmorgan part settlement jpmorgan pay addit usd million solv remain disput lehman report law approv settlement resolv lehman remain claim jpmorgan exampl post petit interest secur lend claim settlement also requir lehman abandon claim regard tassimo case situat jpmorgan act main clear bank lehman broker dealer busi also custodian tri parti repurchas agreement lehman claim jpmorgan dispos firm collater commerci unreason manner improperli claim usd million post petit interest well usd billion jpmorgan paid januari addit fine usd million bring loss amount total usd updat februari loss amount chang usd billion usd billion headlin paragraph chang reflect updat paragraph ad reflect new york court decis consequ',\n",
       " 'deep dive avail loss event decemb hsbc announc statement reach settlement us author relat investig regard inadequ complianc anti money launder sanction law bank make payment total usd billion eur billion agreement includ defer prosecut agreement depart justic doj total includ usd million civil penalti usd billion forfeitur accord bloomberg decemb hsbc announc doj agre allow defer prosecut agreement expir bank said also reach agreement achiev global resolut us govern agenc investig hsbc past conduct relat issu anticip finalis undertak unit kingdom financi servic author fsa shortli statement hsbc said also improv oversight money launder complianc group level adopt new sanction polici worldwid exit correspond relationship risk reason said increas anti money launder staf level tenfold spent usd million remedi measur hsbc said also spend usd million five year review know custom file statement fsa said hsbc would creat post group money launder report offic creat board overse money launder complianc hsbc h report date juli reveal made usd million eur million provis cover potenti us regulatori fine relat investig bank anti money launder control novemb bank increas provis usd million usd billion two week earlier juli us senat perman subcommitte publish report highlight poor anti money launder control hsbc us affili mid mid subcommitte focus five area activ name servic high risk affili circumv offic foreign asset control safeguard disregard terrorist financ link clear suspici bulk travel chequ offer bearer share account bank expos us financi system wide array money launder drug traffick terrorist financ risk due poor anti money launder control subcommitte said juli hsbc mexico fine mxn million usd million eur million mexico nation bank secur commiss cnbv non complianc anti money launder system control failur report suspici transact fine highest penalti impos cnbv repres per cent hsbc mexico net incom end decemb bank formal accus crime juli senat report also alleg bank fail adequ scrutinis transfer mexico iran cayman island saudi arabia syria busi area close link drug cartel terror tax avoid hsbc mexico transfer usd billion hsbc us oper despit warn regul drug cartel could use hsbc account gain access us market report said bank also accus help account holder bypass sanction impos govern iran one case examin subcommitte two hsbc affili sent nearli transact involv usd billion account hsbc bank usa seven year without disclos transact link iran report find updat februari provis flag chang ye follow intern review paragraph amend detail lift defer prosecut agreement']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply it to our text data \n",
    "# dataset is named wine_data and the text are in the column \"wmn\"\n",
    "processed_wmn = [ review_to_words(text) for text in text_total]\n",
    "\n",
    "processed_wmn[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a corpus for the word2vec model\n",
    "def build_corpus(data):\n",
    "    \"Creates a list of lists containing words from each sentence\"\n",
    "    corpus = []\n",
    "    for sentence in data:\n",
    "        word_list = sentence.split(\" \")\n",
    "        corpus.append(word_list)    \n",
    "           \n",
    "    return corpus\n",
    "\n",
    "corpus = build_corpus(processed_wmn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the word2vec algorithm from the gensim library\n",
    "from gensim.models import word2vec\n",
    "# run the model\n",
    "model = word2vec.Word2Vec(corpus, size=100, window=5, min_count=1000, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in model.wv.vocab][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(item[0],round(item[1],2)) for item in model.most_similar('fraud')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "wordList2 = reduce(lambda x,y: x+y,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dG = nx.DiGraph()\n",
    "\n",
    "for i, word in enumerate(wordList2):\n",
    "    try:\n",
    "        next_word = wordList2[i + 1]\n",
    "        if not dG.has_node(word):\n",
    "            dG.add_node(word)\n",
    "            dG.node[word]['count'] = 1\n",
    "        else:\n",
    "            dG.node[word]['count'] += 1\n",
    "        if not dG.has_node(next_word):\n",
    "            dG.add_node(next_word)\n",
    "            dG.node[next_word]['count'] = 0\n",
    "\n",
    "        if not dG.has_edge(word, next_word):\n",
    "            dG.add_edge(word, next_word, weight=float(\"inf\") - 1)\n",
    "        else:\n",
    "            dG.adj[word][next_word]['weight'] -= 1\n",
    "    except IndexError:\n",
    "        if not dG.has_node(word):\n",
    "            dG.add_node(word)\n",
    "            dG.node[word]['count'] = 1\n",
    "        else:\n",
    "            dG.node[word]['count'] += 1\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in dG.nodes():\n",
    "    print('%s:%d\\n' % (node, dG.node[node]['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in dG.edges():\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(dG, dimensions=20, walk_length=16, num_walks=100, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "for node, _ in model.most_similar('tennis'):\n",
    "    # Show only players\n",
    "    #if len(node) > 3:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
